{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaa69c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STATS 607\n",
    "## Week 4.2: GPU programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a229d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's estimate $\\pi$:\n",
    "\n",
    "- $\\pi$ = area of the unit circle.\n",
    "- If we randomly drop a point in the unit square, it will on average fall inside the circle exactly $\\pi/4$ of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acbb55dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "057c493f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pi_mc(rng):\n",
    "    x, y = rng.uniform(-1, 1, size=(2,))\n",
    "    return x ** 2 + y ** 2 <= 1\n",
    "\n",
    "4 * pi_mc(rng).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f37ca9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Monte Carlo converges at rate $n^{-1/2}$. \n",
    "- Therefore if we want an extra decimal point of precision, we need to generate about $100\\times$ more samples.\n",
    "- $\\therefore$ if we want to (naively) estimate $\\pi$ to 8 decimal points, we need about ten quadrillion ($10^{16}$) samples.\n",
    "- (Exercise: compute the exact number. I get $6.7 \\times 10^{15}$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5caf63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving the MC iteration\n",
    "- MC is a simple calculation that we can run in parallel.\n",
    "- Additionally, we don't need to store the intermediate results. \n",
    "- We can use a running sum/average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0d1aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14137308"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba as nb\n",
    "import random\n",
    "\n",
    "@nb.jit(nogil=False)\n",
    "def pi_mc_nb(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        s += x ** 2 + y ** 2 <= 1\n",
    "    return 4 * s / n\n",
    "\n",
    "pi_mc_nb(100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c96e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelization\n",
    "\n",
    "Now let's run in parallel across all processors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8909986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "948484a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.31 s, sys: 62.2 ms, total: 3.37 s\n",
      "Wall time: 3.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ThreadPoolExecutor() as pool:\n",
    "    results = list(pool.map(pi_mc_nb, [10_000_000] * 24))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55a9cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU parallelization\n",
    "\n",
    "There are two ways to interact with GPUs:\n",
    "1. High level (ufuncs, Jax, etc.)\n",
    "2. Low level (write CUDA-ish code)\n",
    "\n",
    "\\#1 almost always adequate. However it will not always \"max out\" the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe56040",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141584608"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@nb.vectorize('int8(float32, float32)', target=\"cuda\")\n",
    "def pi_mc_nb(x, y):\n",
    "    return x ** 2 + y ** 2 <= 1\n",
    "\n",
    "x, y = rng.uniform(size=(2, 1000000000)).astype(np.float32)\n",
    "4 * pi_mc_nb(x, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8d09488",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141646408"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using jax\n",
    "import jax\n",
    "jax.config.update('jax_log_compiles', True)\n",
    "\n",
    "@jax.jit\n",
    "def pi_mc_jax(x, y):\n",
    "    return x ** 2 + y ** 2 <= 1\n",
    "\n",
    "x, y = rng.uniform(size=(2, 1000000000)).astype(np.float32)\n",
    "4 * pi_mc_nb(x, y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee837d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CUDA\n",
    "\n",
    "- Computation in CUDA is organized into grids, blocks and threads.\n",
    "  - Blocks are groups of threads.\n",
    "  - Grids are collections of blocks.\n",
    "  - (Usually there's only one grid.)\n",
    "- Threads are the smallest unit of execution in CUDA.\n",
    "  - Each thread executes a kernel function independently.\n",
    "  - Threads within a block can synchronize with each other and share memory.\n",
    "  - Blocks cannot synchronize (easily), and can only share global memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c254ee3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![threads and blockl](https://upload.wikimedia.org/wikipedia/commons/5/5b/Block-thread.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642279a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concurrency\n",
    "- Threads within a block execute concurrently.\n",
    "- Blocks are scheduled on streaming multiprocessors (SMs) and can run in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5a8e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Memory\n",
    "- Shared Memory: Accessible by all threads within a block. (fast)\n",
    "- Global Memory: Accessible by all threads across all blocks, but has higher latency. (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d757cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    tx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
    "    ty = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\n",
    "\n",
    "    block_size = cuda.blockDim.x  # number of threads per block\n",
    "    grid_size = cuda.gridDim.x    # number of blocks in the grid\n",
    "    \n",
    "    start = tx + ty * block_size\n",
    "    stride = block_size * grid_size\n",
    "\n",
    "    # assuming x and y inputs are same length\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = x[i] + y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325e8f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Memory management\n",
    "- The GPU has its own memory. \n",
    "- Copying to (from) the system memory is called _device to (from) host transfer_.\n",
    "- This can take longer than running the computation! So it can pay to manage this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56349ef1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numba.cuda as cuda\n",
    "\n",
    "@cuda.jit\n",
    "def monte_carlo_pi_kernel(count, rng_states, results):\n",
    "    idx = cuda.grid(1)\n",
    "    s = 0.\n",
    "    n = 2 ** 20\n",
    "    if idx < count:\n",
    "        for i in range(n):\n",
    "            x = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "            y = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "            s += x**2 + y**2 <= 1.0\n",
    "        results[idx] = s / (1. * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bcc08d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592502593994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba.cuda.random\n",
    "\n",
    "def estimate_pi(num_samples):\n",
    "    threads_per_block = 256\n",
    "    blocks = (num_samples + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    rng_states = numba.cuda.random.create_xoroshiro128p_states(num_samples, seed=1)\n",
    "    results = cuda.device_array(num_samples, dtype=np.float32)\n",
    "\n",
    "    monte_carlo_pi_kernel[blocks, threads_per_block](num_samples, rng_states, results)\n",
    "    pi_hat = 4 * results.copy_to_host().mean()\n",
    "    return pi_hat\n",
    "\n",
    "estimate_pi(2 ** 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0887999",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Synchronization\n",
    "- Sometimes you need to synchronize between threads. \n",
    "- For example, suppose we changed our kernel to just write a single count per block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3fcc902",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def monte_carlo_pi_kernel(rng_states, results):\n",
    "    idx = cuda.grid(1)\n",
    "    n = 2 ** 20\n",
    "    s = 0.\n",
    "    for i in range(n):\n",
    "        x = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "        y = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "        s += x**2 + y**2 <= 1.0\n",
    "    results[cuda.blockIdx.x, 0] += s\n",
    "    results[cuda.blockIdx.x, 1] += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d144c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     pi_hat \u001b[38;5;241m=\u001b[39m res[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m res[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pi_hat\n\u001b[0;32m---> 15\u001b[0m \u001b[43mestimate_pi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m, in \u001b[0;36mestimate_pi\u001b[0;34m(num_samples)\u001b[0m\n\u001b[1;32m     10\u001b[0m monte_carlo_pi_kernel[blocks, threads_per_block](rng_states, results)\n\u001b[1;32m     11\u001b[0m res \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mcopy_to_host()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m pi_hat \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m res[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pi_hat\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import numba.cuda.random\n",
    "import numpy as np\n",
    "\n",
    "def estimate_pi(num_samples):\n",
    "    threads_per_block = 256\n",
    "    assert num_samples % 256 == 0\n",
    "    blocks = num_samples // threads_per_block\n",
    "    rng_states = numba.cuda.random.create_xoroshiro128p_states(num_samples, seed=1)\n",
    "    results = cuda.to_device(np.zeros([blocks, 2]))\n",
    "    monte_carlo_pi_kernel[blocks, threads_per_block](rng_states, results)\n",
    "    res = results.copy_to_host().sum(0)\n",
    "    pi_hat = res[:, 0] / res[:, 1]\n",
    "    return pi_hat\n",
    "\n",
    "estimate_pi(1024 * 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cc06818",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mblocks\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blocks' is not defined"
     ]
    }
   ],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b25e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
