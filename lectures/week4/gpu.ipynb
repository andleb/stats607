{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaa69c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STATS 607\n",
    "## Week 4.2: GPU programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a229d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's estimate $\\pi$:\n",
    "\n",
    "- $\\pi$ = area of the unit circle.\n",
    "- If we randomly drop a point in the unit square, it will on average fall inside the circle exactly $\\pi/4$ of the time."
   ]
  },
  {
   "cell_type": "code",
   "id": "acbb55dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2024-11-13T18:13:30.870101Z",
     "start_time": "2024-11-13T18:13:30.723727Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng(1)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "057c493f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2024-11-13T18:20:31.631406Z",
     "start_time": "2024-11-13T18:20:31.627290Z"
    }
   },
   "source": [
    "def pi_mc(rng):\n",
    "    x, y = rng.uniform(-1, 1, size=(2,))\n",
    "    return x ** 2 + y ** 2 <= 1\n",
    "\n",
    "4 * pi_mc(rng).mean()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "70f37ca9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Monte Carlo converges at rate $n^{-1/2}$. \n",
    "- Therefore if we want an extra decimal point of precision, we need to generate about $100\\times$ more samples.\n",
    "- $\\therefore$ if we want to (naively) estimate $\\pi$ to 8 decimal points, we need about ten quadrillion ($10^{16}$) samples.\n",
    "- (Exercise: compute the exact number. I get $6.7 \\times 10^{15}$.)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Anti-thetic variates:",
   "id": "b543e2fff2f7c27e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:20:08.336308Z",
     "start_time": "2024-11-13T18:20:08.333296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pi_mc_antithetic(rng):\n",
    "    x, y = rng.uniform(-1, 1, size=(2,))\n",
    "    return (x ** 2 + y ** 2 <= 1) + (x ** 2 + y ** 2 <= 1)"
   ],
   "id": "be1f31079411a2bb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:20:11.656356Z",
     "start_time": "2024-11-13T18:20:11.652392Z"
    }
   },
   "cell_type": "code",
   "source": "4 * pi_mc_antithetic(rng).mean()",
   "id": "a6ca9cfa080b726c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "8a5caf63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving the MC iteration\n",
    "- MC is a simple calculation that we can run in parallel.\n",
    "- Additionally, we don't need to store the intermediate results. \n",
    "- We can use a running sum/average."
   ]
  },
  {
   "cell_type": "code",
   "id": "8c0d1aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:27:27.812245Z",
     "start_time": "2024-11-13T18:27:26.438095Z"
    }
   },
   "source": [
    "import numba as nb\n",
    "import random\n",
    "\n",
    "@nb.jit(nogil=True)\n",
    "def pi_mc_nb(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        s += x ** 2 + y ** 2 <= 1\n",
    "    return 4 * s / n\n",
    "\n",
    "pi_mc_nb(100000000)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14178736"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "7a3c96e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelization\n",
    "\n",
    "Now let's run in parallel across all processors:"
   ]
  },
  {
   "cell_type": "code",
   "id": "8909986d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:23:13.346865Z",
     "start_time": "2024-11-13T18:23:13.331330Z"
    }
   },
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "948484a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:27:38.168870Z",
     "start_time": "2024-11-13T18:27:34.735084Z"
    }
   },
   "source": [
    "%%time\n",
    "with ProcessPoolExecutor() as pool:\n",
    "    results = list(pool.map(pi_mc_nb, [10_000_000] * 24))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 ms, sys: 40.1 ms, total: 61.5 ms\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:27:31.386951Z",
     "start_time": "2024-11-13T18:27:30.636151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "with ThreadPoolExecutor() as pool:\n",
    "    results = list(pool.map(pi_mc_nb, [10_000_000] * 24))"
   ],
   "id": "742452a89e356cbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 21.3 ms, total: 3.39 s\n",
      "Wall time: 747 ms\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:28:01.267529Z",
     "start_time": "2024-11-13T18:28:01.263443Z"
    }
   },
   "cell_type": "code",
   "source": "np.mean(results)",
   "id": "796c2febe5644205",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.1417484833333336)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "3a55a9cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU parallelization\n",
    "\n",
    "There are two ways to interact with GPUs:\n",
    "1. High level (ufuncs, Jax, etc.)\n",
    "2. Low level (write CUDA-ish code)\n",
    "\n",
    "\\#1 almost always adequate. However it will not always \"max out\" the GPU."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NumPy ufuncs",
   "id": "c85b80401d6d0e86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "what's `int8` below: the return type!",
   "id": "5e9d152984e252ea"
  },
  {
   "cell_type": "code",
   "id": "4fe56040",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "@nb.vectorize('int8(float32, float32)', target=\"cuda\")\n",
    "def pi_mc_nb(x, y):\n",
    "    return x ** 2 + y ** 2 <= 1\n",
    "\n",
    "x, y = rng.uniform(size=(2, 1000000000)).astype(np.float32)\n",
    "4 * pi_mc_nb(x, y).mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8d09488",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "end_time": "2024-11-13T18:36:56.114818Z",
     "start_time": "2024-11-13T18:35:13.732230Z"
    }
   },
   "source": [
    "# Using jax\n",
    "import jax\n",
    "jax.config.update('jax_log_compiles', True)\n",
    "\n",
    "@jax.jit\n",
    "def pi_mc_jax(x, y):\n",
    "    return x ** 2 + y ** 2 <= 1\n",
    "\n",
    "x, y = rng.uniform(size=(2, 1000000000)).astype(np.float32)\n",
    "4 * pi_mc_nb(x, y).mean()"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 9\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;129m@jax\u001B[39m\u001B[38;5;241m.\u001B[39mjit\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpi_mc_jax\u001B[39m(x, y):\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m y \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m----> 9\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[43mrng\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muniform\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000000000\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m*\u001B[39m pi_mc_nb(x, y)\u001B[38;5;241m.\u001B[39mmean()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "f9ee837d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CUDA\n",
    "\n",
    "- Computation in CUDA is organized into grids, blocks and threads.\n",
    "  - Blocks are groups of threads.\n",
    "  - Grids are collections of blocks.\n",
    "  - (Usually there's only one grid.)\n",
    "- Threads are the smallest unit of execution in CUDA.\n",
    "  - Each thread executes a kernel function independently.\n",
    "  - Threads within a block can synchronize with each other and share memory.\n",
    "  - Blocks cannot synchronize (easily), and can only share global memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c254ee3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![threads and blockl](https://upload.wikimedia.org/wikipedia/commons/5/5b/Block-thread.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642279a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concurrency\n",
    "- Threads within a block execute concurrently.\n",
    "- Blocks are scheduled on streaming multiprocessors (SMs) and can run in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5a8e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Memory\n",
    "- Shared Memory: Accessible by all threads within a block. (fast)\n",
    "- Global Memory: Accessible by all threads across all blocks, but has higher latency. (slow)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Basically, run the same thing over the first thread in each block:",
   "id": "9afca4a16984bcf8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d757cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    tx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
    "    ty = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\n",
    "\n",
    "    block_size = cuda.blockDim.x  # number of threads per block\n",
    "    grid_size = cuda.gridDim.x    # number of blocks in the grid\n",
    "    \n",
    "    start = tx + ty * block_size\n",
    "    stride = block_size * grid_size\n",
    "\n",
    "    # assuming x and y inputs are same length\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = x[i] + y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325e8f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Memory management\n",
    "- The GPU has its own memory. \n",
    "- Copying to (from) the system memory is called _device to (from) host transfer_.\n",
    "- This can take longer than running the computation! So it can pay to manage this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56349ef1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numba.cuda as cuda\n",
    "\n",
    "@cuda.jit\n",
    "def monte_carlo_pi_kernel(count, rng_states, results):\n",
    "    idx = cuda.grid(1)\n",
    "    s = 0.\n",
    "    n = 2 ** 20\n",
    "    if idx < count:\n",
    "        for i in range(n):\n",
    "            x = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "            y = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "            s += x**2 + y**2 <= 1.0\n",
    "        results[idx] = s / (1. * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bcc08d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592502593994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba.cuda.random\n",
    "\n",
    "def estimate_pi(num_samples):\n",
    "    threads_per_block = 256\n",
    "    blocks = (num_samples + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    rng_states = numba.cuda.random.create_xoroshiro128p_states(num_samples, seed=1)\n",
    "    results = cuda.device_array(num_samples, dtype=np.float32)\n",
    "\n",
    "\n",
    "    # NOTE: the square brackets notation is used to spell out the geometry of the grid\n",
    "    monte_carlo_pi_kernel[blocks, threads_per_block](num_samples, rng_states, results)\n",
    "    pi_hat = 4 * results.copy_to_host().mean()\n",
    "    return pi_hat\n",
    "\n",
    "estimate_pi(2 ** 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0887999",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Synchronization\n",
    "- Sometimes you need to synchronize between threads. \n",
    "- For example, suppose we changed our kernel to just write a single count per block:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T19:11:57.037312Z",
     "start_time": "2024-11-13T19:11:57.030745Z"
    }
   },
   "cell_type": "code",
   "source": "import numba.cuda as cuda",
   "id": "541e66138a531ff8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3fcc902",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def monte_carlo_pi_kernel(rng_states, results):\n",
    "    idx = cuda.grid(1)\n",
    "    n = 2 ** 20\n",
    "    s = 0.\n",
    "    for i in range(n):\n",
    "        x = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "        y = cuda.random.xoroshiro128p_uniform_float32(rng_states, idx)\n",
    "        s += x**2 + y**2 <= 1.0\n",
    "        \n",
    "    # results[cuda.blockIdx.x, 0] += s\n",
    "    cuda.atomicAdd(results, idx, s)\n",
    "    # results[cuda.blockIdx.x, 1] += n\n",
    "    cuda.atomicAdd(results, idx, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d144c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m     pi_hat \u001B[38;5;241m=\u001B[39m res[:, \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m res[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pi_hat\n\u001B[0;32m---> 15\u001B[0m \u001B[43mestimate_pi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[18], line 12\u001B[0m, in \u001B[0;36mestimate_pi\u001B[0;34m(num_samples)\u001B[0m\n\u001B[1;32m     10\u001B[0m monte_carlo_pi_kernel[blocks, threads_per_block](rng_states, results)\n\u001B[1;32m     11\u001B[0m res \u001B[38;5;241m=\u001B[39m results\u001B[38;5;241m.\u001B[39mcopy_to_host()\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 12\u001B[0m pi_hat \u001B[38;5;241m=\u001B[39m \u001B[43mres\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m/\u001B[39m res[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pi_hat\n",
      "\u001B[0;31mIndexError\u001B[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import numba.cuda.random\n",
    "import numpy as np\n",
    "\n",
    "def estimate_pi(num_samples):\n",
    "    threads_per_block = 256\n",
    "    assert num_samples % 256 == 0\n",
    "    blocks = num_samples // threads_per_block\n",
    "    rng_states = numba.cuda.random.create_xoroshiro128p_states(num_samples, seed=1)\n",
    "    results = cuda.to_device(np.zeros([blocks, 2]))\n",
    "    monte_carlo_pi_kernel[blocks, threads_per_block](rng_states, results)\n",
    "    res = results.copy_to_host().sum(0)\n",
    "    pi_hat = res[:, 0] / res[:, 1]\n",
    "    return pi_hat\n",
    "\n",
    "estimate_pi(1024 * 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cc06818",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mblocks\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'blocks' is not defined"
     ]
    }
   ],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b25e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
